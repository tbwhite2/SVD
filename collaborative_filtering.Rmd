---
title: "Collaborative Filtering"
author: "Bryan"
date: "10/22/2019"
output: html_document
---



Instead of using traits of the features (user/item features) to deterimine 
similarity - focus on the similarty of the user ratings for two items.  

```{r}
data = matrix(data = c(4, NA, NA, 5, 1, NA, NA,
                       5, 5, 4, NA, NA, NA, NA,
                       NA, NA, NA, 2, 4, 5, NA,
                       NA, 3, NA, NA, NA, NA, 3), 
              ncol = 7, byrow = T)
print(data)
```

In place of an item-profile vector for an item we use its column in the utility 
matrix.


## Jaccard Distance

Ignores rating values, looks instead to see which items that
two users have both reviewed and compares that intersection to the total number
of items the users have reviewed.  This works great for occurance data, such
as 'has viewed video' or 'has purchased item' but can lead to counterintuitive 
results if your data is enriched with a scale for its utility matrix, such as 
'count of purchases' or 'rating'.  This point is illustrated below - 
```{r}
jaccard_distance = function(x, y){
  intersection = length(which(x & y))
  union = length(which(x | y))
  1 - (intersection/union)
}
#A + B
jaccard_distance(data[1,], data[2,])
#A + C
jaccard_distance(data[1,], data[3,])
```

Although users A and C have VERY different opinions on products 4 and 5, they 
will be marked as more similar to each other than A and B - even though A and B
both seem to like product 1.

### Rounding the data

One solution to the problem illustrated above is to round the data so that high
ratings (3+) count as a 1 and low ratings count as a zero - same as being unrated.
This would change the utility martix to look like :
```{r}
round_matrix = function(mat, threshold){
  (mat > threshold)*1
}

rounded_data = round_matrix(data, 3)
print(rounded_data)

```

Now when we calculate the Jaccard distance, A and B are more similar than A and 
C.
```{r}
#A + B
jaccard_distance(rounded_data[1,], rounded_data[2,])
#A + C
jaccard_distance(rounded_data[1,], rounded_data[3,])
```



## Cosine Distance 

Measures the cosine of the angle between two vectors projected in a multidimensional 
space (groovy). Larger values indicate smaller angles between the vector,
meaning more similar vectors.  One drawback of cosine similarity is that it must
have missing values filled in - here I chose zeros - but this may not always be
appropriate.  For example filling with 0 in a rating would be the same as saying 
the user hated all movies they haven't seen.

```{r}
cosine_distance = function(x, y, missing_fill = 0){
  x[is.na(x)] = missing_fill
  y[is.na(y)] = missing_fill
  1 - c((x %*% y)/sqrt(sum(x^2)*sum(y^2)))
}
cosine_distance(x = data[1,], y = data[2,])
```

### Normalize Ratings

```{r}
normalize = function(x){
  x - mean(x, na.rm = T)
}

normalize_matrix = function(mat){
  t(apply(mat, 1, normalize))
}

normalized_data = normalize_matrix(data)
print(normalized_data)


```

```{r}
cosine_distance(x = normalized_data[1,], y = normalized_data[2,])
cosine_distance(x = normalized_data[1,], y = normalized_data[3,])
```


## Putting it all together - Making Predictions

You can view the utility matrix as telling us about user or items, or both - all
of the previous examples were focused on finding similar users, but we could 
flip the dimension (choose column instead of rows) and find similar items.

One way of making predictions for a given user is to find some number of other
similar users and average their ratings for each item.  In general it is best
to normalize ratings as some users typically rate higher or lower than others.

We can also flip this problem to use items by finding some number of other 
similar items to a given item.  A user that likes the given item will probably
like something similar.  Normalization of ratings is advised for the same reasons 
as above.

Item item similarity tends to provide more reliable information as it is usually
easier to find items with similar traits than it is to find users that only like
specific subsets of traits - but this guideline depends on what your utility 
matrix is capturing and the behavior of your system.


Below I've implemented an item based movie recommender based on the movielens 
small current dataset (full datasets here : https://grouplens.org/datasets/movielens/).
The details for how and why I 
manipulated the movielens data the way I did are for another post, but it 
should allow for some fun exploration.  

The function find_similar takes a given movie and will return n movie suggestions based
on the provided user ratings matrix and the distance measure provided.  Because
of the way I've paramterized this, you should be able to switch in any distance 
metric you want and tune the ratings matrix as you see fit!  Additionally, the
function can be column or row based, meaning that while below I've tested out
an item based recommender, extending this idea to be a user based recommender
is as simple as changing the margin to 1.

The wrapper function of find_similar_movies allows for a cleaner experience of
user inputing a movie name and some filtering parameters to get a data.table
of similar movies and their meta data.

```{r}
source('prep_movielens.R')

ml_ratings = get_ml_ratings(file_location = './movielens_data/ratings.csv')

user_row_keys = ml_ratings[,1,with = F]
ratings_matrix = as.matrix(ml_ratings[,-1, with = F])

movie_data = get_movies(file_location = './movielens_data/movies.csv')

find_similar = function(index,margin,matrix,dist_func){
  
  if (margin == 1) {
    apply(matrix,1,FUN = get(dist_func), y = matrix[index,])
  }else if (margin == 2) {
    as.vector(apply(matrix,2,FUN = get(dist_func), y = matrix[,index]))
  }else{
    stop('margin must be 1 (rows) or 2 (cols)')
  }
}



find_similar_movies = function(movie_name, n, distance_func, ratings_data, movie_data){
  movie_id = movie_data[movie_title == movie_name]$movieId
  movie_index = which(colnames(ratings_data) == movie_id)
  
  similar_movies = find_similar(index = movie_index,
                                margin = 2,
                                matrix = ratings_data,
                                dist_func = distance_func)

  similar_index = head(order(similar_movies), n + 1)
  similar_ids = colnames(ratings_data)[similar_index]
  
  similar_movies_dt = data.table(target_movie_title = movie_name,
                                 target_movieId = movie_id,
                                 movieId = as.integer(similar_ids))
  
  merge(similar_movies_dt[movieId != target_movieId],movie_data)
  
}
```

Below we can see the impact of the considerations we mentioned above for normalization, 
rounding and distance measure choice - based on my experiments, the best parameters
truely depend on the type of movie being estimated, for example, one of my favorite 
movies, 'The Grand Budapest Hotel' got pretty good (for me) recommendations on all 
of the below configurations, except for normalized cosine.  This could be due to 
the normalization method - but highlights the fact that there is never one best 
solution and that experimentation and tuning are needed to improve results!

```{r}
analysis_movie = "Grand Budapest Hotel, The"
```

```{r}
similar_movies = find_similar_movies(movie_name = analysis_movie,
                    n = 10, 
                    distance_func = 'jaccard_distance', 
                    ratings_data = ratings_matrix, 
                    movie_data = movie_data)
similar_movies$movie_title
```


```{r}
similar_movies = find_similar_movies(movie_name = analysis_movie,
                    n = 10, 
                    distance_func = 'jaccard_distance', 
                    ratings_data = round_matrix(ratings_matrix, threshold = 4), 
                    movie_data = movie_data)
similar_movies$movie_title

```




```{r}
similar_movies = find_similar_movies(movie_name = analysis_movie,
                    n = 10, 
                    distance_func = 'cosine_distance', 
                    ratings_data = ratings_matrix, 
                    movie_data = movie_data)
similar_movies$movie_title
```

```{r}
similar_movies = find_similar_movies(movie_name = analysis_movie,
                    n = 10, 
                    distance_func = 'cosine_distance', 
                    ratings_data = normalize_matrix(ratings_matrix), 
                    movie_data = movie_data)
similar_movies$movie_title
```


Interestingly - there 
was a good bit of overlap across all methods for recommendations for many of the movies

